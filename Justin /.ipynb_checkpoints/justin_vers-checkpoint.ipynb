{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35346ac7-1642-40c7-ab4c-99b772c6eb61",
   "metadata": {},
   "source": [
    "# 1. Speech to text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ec2f5a-2468-4f95-abac-2f4903159f80",
   "metadata": {},
   "source": [
    "## 1.1. Install library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6404a80-fb9d-4839-8756-6c15db6bf0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install SpeechRecognition pydub\n",
    "import speech_recognition as sr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e41e949-6c13-452c-aa02-26c1a7b33b86",
   "metadata": {},
   "source": [
    "## 1.2. Specify file location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90eae268-7507-440e-97bf-5cb580117ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"/Users/justinshin/Desktop/Bootcamp/final_project/From-motion-to-emotion/Elyesa/1_speech_to_text_short.wav\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e9047e-cfa2-41ff-8b15-938a9c204329",
   "metadata": {},
   "source": [
    "## 1.3. Audio to text covertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c8598fb-b650-4731-b531-edfde5e3233b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result2:\n",
      "{   'alternative': [   {   'confidence': 0.93603683,\n",
      "                           'transcript': \"I believe you're just talking \"\n",
      "                                         'nonsense'},\n",
      "                       {   'transcript': 'I believe you are just talking '\n",
      "                                         'nonsense'},\n",
      "                       {'transcript': 'I believe your just talking nonsense'},\n",
      "                       {   'transcript': 'I believe you were just talking '\n",
      "                                         'nonsense'}],\n",
      "    'final': True}\n",
      "I believe you're just talking nonsense\n"
     ]
    }
   ],
   "source": [
    "r = sr.Recognizer()\n",
    "\n",
    "# open the file\n",
    "with sr.AudioFile(filename) as source:\n",
    "    # listen for the data (load audio to memory)\n",
    "    audio_data = r.record(source)\n",
    "    # recognize (convert from speech to text)\n",
    "    text = r.recognize_google(audio_data)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed270ca-515a-4bb9-bbd4-c1bb099781ab",
   "metadata": {},
   "source": [
    "# 2. Sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dd01c9-41d3-4e9c-9360-c53b446b885c",
   "metadata": {},
   "source": [
    "## 2.1. Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45fd7a3d-df3c-4675-b6a6-736a9592423f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c26ad3-15e7-4515-a2f9-b07a8a534c13",
   "metadata": {},
   "source": [
    "## 2.2. Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1dc156a1-c9c4-48e0-a5ee-e2a667b52c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I believe you're just talking nonsense\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6147a1f7-a1a0-4a90-a45b-a607b7319fb8",
   "metadata": {},
   "source": [
    "## 2.3. Token NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f7b9b61-bbd4-4ab2-9afc-bcd5e444852a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'believe', 'you', \"'re\", 'just', 'talking', 'nonsense']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = nltk.word_tokenize(text)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "527ba4ab-dfc5-4c55-884e-d1d8d801e46b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'PRP'),\n",
       " ('believe', 'VBP'),\n",
       " ('you', 'PRP'),\n",
       " (\"'re\", 'VBP'),\n",
       " ('just', 'RB'),\n",
       " ('talking', 'VBG'),\n",
       " ('nonsense', 'NN')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged = nltk.pos_tag(tokens)\n",
    "tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eecf66b7-d95f-4f73-b42c-e58f1e1c999e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S I/PRP believe/VBP you/PRP 're/VBP just/RB talking/VBG nonsense/NN)\n"
     ]
    }
   ],
   "source": [
    "entities = nltk.chunk.ne_chunk(tagged)\n",
    "entities.pprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d335bcb-9ef3-4386-912e-22aad235d0b7",
   "metadata": {},
   "source": [
    "## 2.4. NLTK SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "555df7c1-7b3b-406f-abca-d4b0511fbd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = sia.polarity_scores(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "95df35ea-05c8-499a-af92-a69ca3bb1026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.403, 'neu': 0.597, 'pos': 0.0, 'compound': -0.4019}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "55018536-1dae-4e22-835c-afea46c0b7df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neu'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(sentiment, key=sentiment.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d74e847-3942-457e-a7bd-dd1444863626",
   "metadata": {},
   "source": [
    "# 3. Emotion detecting from voice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11546aae-7bc6-40eb-9934-7eccef5129eb",
   "metadata": {},
   "source": [
    "## 3.1. Visualize Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dd806feb-45d9-4bc9-bd41-1184d00262fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave\n",
    "wav_obj = wave.open(filename, 'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cb400847-0c68-4699-8733-07d8e18cc934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A sound wave is a continuous quantity that needs to be sampled at some time interval to digitize it. \n",
    "# The sampling rate quantifies how many samples of the sound are taken every second.\n",
    "sample_freq = wav_obj.getframerate()\n",
    "sample_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a962ca-1711-4b4a-b92c-eed560b872c2",
   "metadata": {},
   "source": [
    "The sample frequency quantifies the number of samples per second. In this case, it is 46,400 times per second, which corresponds to CD quality. The number of individual frames, or samples, is given by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ce7816b5-fb38-42c7-8875-116d66cc5e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46400"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples = wav_obj.getnframes()\n",
    "n_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2912931-dc57-4286-8b86-0627dba4fb8d",
   "metadata": {},
   "source": [
    "We can now calculate how long our audio file is in seconds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4a6fa31c-8bc1-48bc-9692-cd169198bd8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how long the audio file is in seconds\n",
    "t_audio = n_samples/sample_freq\n",
    "t_audio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9769ce1-09dd-4cd7-ba64-69ddb9b614a5",
   "metadata": {},
   "source": [
    "The audio file is recorded in stereo, that is, in two independent audio channels. This creates the impression of the sound coming from two different directions. We can check the number of channels as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ff299f22-8f8a-4353-911a-233116e57ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_channels = wav_obj.getnchannels()\n",
    "n_channels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80087861-93cb-489f-81df-16b307fd718f",
   "metadata": {},
   "source": [
    "The next step is to get the values of the signal, that is, the amplitude of the wave at that point in time. To do this, we can use the readframes() method, which takes one argument, n, defining the number of frames to read:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b587a6b7-76f0-4f10-a4f6-816b2666dbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_wave = wav_obj.readframes(n_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af850cf-6759-4c36-a971-54c780adb708",
   "metadata": {},
   "source": [
    "This method returns a bytes object. Check for yourself by using the type() built-in function on the signal_wave object. To get signal values from this, we have to turn to numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "46709384-c1d6-420d-bda2-1bb03b49a090",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "signal_array = np.frombuffer(signal_wave, dtype=np.int16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42955ffa-19a1-47da-8d26-5476aa2fbf8b",
   "metadata": {},
   "source": [
    "This returns all data from both channels as a 1-dimensional array. If you check the shape of signal_array, you notice it has 10,768,652 elements, which is exactly n_samples * n_channels. To split the data into individual channels, we can use a clever little array slice trick:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8c5cd15a-1142-4c4c-a9ec-fa05c2c34a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_channel = signal_array[0::2]\n",
    "r_channel = signal_array[1::2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842c69db-a1d9-4ef6-aac8-62d5f99b5cc1",
   "metadata": {},
   "source": [
    "Now, our left and right channels are separated, both containing 5,384,326 integers representing the amplitude of the signal.\n",
    "\n",
    "Next, we show some examples of how to plot the signal values. We have our data stored in arrays here, but for many data science applications, pandas is very useful. Check out THIS ARTICLE about visualizing data stored in a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "47f5bce6-1f41-4f8d-9f88-30c8b173ceec",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = np.linspace(0, n_samples/sample_freq, num=n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d646898d-4e14-4e25-8ee5-b20b95782fca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (46400,) and (23200,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [34]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[0;32m----> 3\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml_channel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLeft Channel\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSignal Value\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/matplotlib/pyplot.py:2757\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2755\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[1;32m   2756\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\u001b[38;5;241m*\u001b[39margs, scalex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, scaley\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 2757\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2758\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscalex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscalex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaley\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaley\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2759\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/matplotlib/axes/_axes.py:1632\u001b[0m, in \u001b[0;36mAxes.plot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1391\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[1;32m   1392\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1629\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[1;32m   1630\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1631\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[0;32m-> 1632\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[1;32m   1633\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[1;32m   1634\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/matplotlib/axes/_base.py:312\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    310\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    311\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 312\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/matplotlib/axes/_base.py:498\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs)\u001b[0m\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m--> 498\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    499\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    502\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (46400,) and (23200,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(times, l_channel)\n",
    "plt.title('Left Channel')\n",
    "plt.ylabel('Signal Value')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.xlim(0, t_audio)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
